{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example of the creation of the model on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages used\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the functions used in feature extraction\n",
    "def rms(data):\n",
    "    return np.sqrt(np.mean(np.square(data)))\n",
    "\n",
    "\n",
    "def sra(data):\n",
    "    return np.square(np.mean(np.sqrt(np.abs(data))))\n",
    "\n",
    "\n",
    "def kv(data):\n",
    "    return np.mean(np.power((data - np.mean(data))/np.std(data), 4))\n",
    "\n",
    "\n",
    "def sv(data):\n",
    "    return np.mean(np.power((data - np.mean(data)) / np.std(data), 3))\n",
    "\n",
    "\n",
    "def p2pv(data):\n",
    "    return np.max(data) - np.min(data)\n",
    "\n",
    "\n",
    "def cf(data):\n",
    "    return np.max(np.abs(data))/np.sqrt(np.mean(np.square(data)))\n",
    "\n",
    "\n",
    "def imf(data):\n",
    "    return np.max(np.abs(data))/np.mean(np.abs(data))\n",
    "\n",
    "\n",
    "def mf(data):\n",
    "    return np.max(np.abs(data))/np.square(np.mean(np.sqrt(np.abs(data))))\n",
    "\n",
    "\n",
    "def sf(data):\n",
    "    return np.max(np.abs(data))/np.sqrt(np.mean(np.square(data)))\n",
    "\n",
    "\n",
    "def kf(data):\n",
    "    return np.mean(np.power((data - np.mean(data)/np.std(data)), 4))/np.square(np.mean(np.square(data)))\n",
    "\n",
    "\n",
    "def dfa(data):\n",
    "    return nolds.dfa(data)\n",
    "\n",
    "\n",
    "def npeaks(data, threshold):\n",
    "    return len(detect_peaks(data, threshold=threshold))\n",
    "\n",
    "\n",
    "def fc(data):\n",
    "    fft = np.fft.fft(data)\n",
    "    return np.mean(np.abs(fft[1:len(fft) // 2]))\n",
    "\n",
    "\n",
    "def rmsf(data):\n",
    "    fft = np.fft.fft(data)\n",
    "    return np.sqrt(np.mean(np.abs(fft[1:len(fft) // 2])))\n",
    "\n",
    "\n",
    "def rvf(data):\n",
    "    fft = np.fft.fft(data)\n",
    "    return np.sqrt(np.mean(np.square(np.abs(fft[1:len(fft) // 2]) - fc(data))))\n",
    "\n",
    "\n",
    "def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='rising',\n",
    "                 kpsh=False, valley=False, ax=None):\n",
    "    x = np.atleast_1d(x).astype('float64')\n",
    "    if x.size < 3:\n",
    "        return np.array([], dtype=int)\n",
    "    if valley:\n",
    "        x = -x\n",
    "        if mph is not None:\n",
    "            mph = -mph\n",
    "    # find indices of all peaks\n",
    "    dx = x[1:] - x[:-1]\n",
    "    # handle NaN's\n",
    "    indnan = np.where(np.isnan(x))[0]\n",
    "    if indnan.size:\n",
    "        x[indnan] = np.inf\n",
    "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
    "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
    "    if not edge:\n",
    "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "    else:\n",
    "        if edge.lower() in ['rising', 'both']:\n",
    "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
    "        if edge.lower() in ['falling', 'both']:\n",
    "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
    "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
    "    # handle NaN's\n",
    "    if ind.size and indnan.size:\n",
    "        # NaN's and values close to NaN's cannot be peaks\n",
    "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan - 1, indnan + 1))), invert=True)]\n",
    "    # first and last values of x cannot be peaks\n",
    "    if ind.size and ind[0] == 0:\n",
    "        ind = ind[1:]\n",
    "    if ind.size and ind[-1] == x.size - 1:\n",
    "        ind = ind[:-1]\n",
    "    # remove peaks < minimum peak height\n",
    "    if ind.size and mph is not None:\n",
    "        ind = ind[x[ind] >= mph]\n",
    "    # remove peaks - neighbors < threshold\n",
    "    if ind.size and threshold > 0:\n",
    "        dx = np.min(np.vstack([x[ind] - x[ind - 1], x[ind] - x[ind + 1]]), axis=0)\n",
    "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
    "    # detect small peaks closer than minimum peak distance\n",
    "    if ind.size and mpd > 1:\n",
    "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
    "        idel = np.zeros(ind.size, dtype=bool)\n",
    "        for i in range(ind.size):\n",
    "            if not idel[i]:\n",
    "                # keep peaks with the same height if kpsh is True\n",
    "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
    "                       & (x[ind[i]] > x[ind] if kpsh else True)\n",
    "                idel[i] = 0  # Keep current peak\n",
    "        # remove the small peaks and sort back the indices by their occurrence\n",
    "        ind = np.sort(ind[~idel])\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []  # the lsit that will contain the samples\n",
    "y = []  # the lsit that will contain the labels\n",
    "rates = []  # the lsit that will contain the rates\n",
    "\n",
    "EXT = \"*.csv\"\n",
    "\n",
    "PATH = r'path_to_the_folder\\synthetic_data\\label_1'\n",
    "sand_csv_files = [file for path, subdir, files in os.walk(PATH) for file in glob(os.path.join(path, EXT))]\n",
    "\n",
    "for filename in sand_csv_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    x.append(df)\n",
    "    y.append(1)\n",
    "\n",
    "PATH = r'path_to_the_folder\\synthetic_data\\label_0'\n",
    "nosand_csv_files = [file for path, subdir, files in os.walk(PATH) for file in glob(os.path.join(path, EXT))]\n",
    "\n",
    "for filename in nosand_csv_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    x.append(df)\n",
    "    y.append(0)\n",
    "\n",
    "\n",
    "main_df = pd.DataFrame(index=range(0, len(x)),\n",
    "                       columns=['ac_mean', 'ac_std', 'ac_rms', 'ac_sra', 'ac_p2pv', 'ac_n_peaks', 'ac_fc', 'ac_rmsf', 'ac_rvf',\n",
    "                                'chk_min', 'chk_std', 'chk_del_sum', 'chk_del_abs_sum', 'alloc_liq', 'alloc_gas'])\n",
    "\n",
    "T = 9  # sample rate\n",
    "N = 100 # length of signals\n",
    "fs = np.linspace(0, 1 / T, N) # frequencies for FFT\n",
    "\n",
    "# extracting features from all samples\n",
    "for i in range(len(x)):\n",
    "    df = x[i].copy()\n",
    "    main_df.loc[i, 'ac_mean'] = df['ac'].mean()\n",
    "    main_df.loc[i, 'ac_std'] = np.std(df['ac'])\n",
    "    main_df.loc[i, 'ac_rms'] = rms(df['ac'].values)\n",
    "    main_df.loc[i, 'ac_sra'] = sra(df['ac'].values)\n",
    "    main_df.loc[i, 'ac_p2pv'] = p2pv(df['ac'].values)\n",
    "    main_df.loc[i, 'ac_n_peaks'] = npeaks(df['ac'].values, threshold=0)\n",
    "    main_df.loc[i, 'ac_fc'] = fc(df['ac'].values)\n",
    "    main_df.loc[i, 'ac_rmsf'] = rmsf(df['ac'].values)\n",
    "    main_df.loc[i, 'ac_rvf'] = rvf(df['ac'].values)\n",
    "\n",
    "    main_df.loc[i, 'chk_min'] = np.min(df['chk'].values)\n",
    "    main_df.loc[i, 'chk_std'] = np.std(df['chk'].values)\n",
    "    main_df.loc[i, 'chk_del_sum'] = df['chk'].diff().fillna(0).sum()\n",
    "    main_df.loc[i, 'chk_del_abs_sum'] = df['chk'].diff().fillna(0).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_0 = pd.read_csv(r'path_to_the_folder\\synthetic_data/rates_0.csv')\n",
    "rates_1 = pd.read_csv(r'path_to_the_folder\\synthetic_data/rates_1.csv')\n",
    "\n",
    "oil_0 = rates_0['oil'].values\n",
    "oil_1 = rates_1['oil'].values\n",
    "oil = np.append(oil_1, oil_0)\n",
    "\n",
    "water_0 = rates_0['water'].values\n",
    "water_1 = rates_1['water'].values\n",
    "water = np.append(water_1, water_0)\n",
    "\n",
    "gas_0 = rates_0['gas'].values\n",
    "gas_1 = rates_1['gas'].values\n",
    "gas = np.append(gas_1, gas_0)\n",
    "\n",
    "main_df['alloc_liq'] = oil + water\n",
    "main_df['alloc_gas'] = gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.replace([np.inf, -np.inf], 0)\n",
    "main_df = main_df.fillna(0)\n",
    "X_train = main_df\n",
    "\n",
    "y = np.array(y, dtype='int')\n",
    "# y_train = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1, class_weight=\"balanced\")\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'path_to_a_directory')\n",
    "filename = 'RFC_v3.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
